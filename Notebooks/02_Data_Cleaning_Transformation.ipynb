{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ3MVWOu8Vmi",
        "outputId": "5a29274e-2e96-48f3-c94d-6dc4a3f6430c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# If you restarted the runtime, mount Drive again\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Reuse existing Spark session created in Notebook 01\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/spark-3.3.2-bin-hadoop3\n",
        "!rm -rf spark-3.3.2-bin-hadoop3.tgz\n"
      ],
      "metadata": {
        "id": "pTvQ32LVmvns"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -qq > /dev/null\n",
        "!apt-get install -qq openjdk-11-jdk-headless > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
        "!tar -xzf spark-3.5.1-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "6eSUjy82m01n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "badd8e58-3780-4952-c844-9d386bca102a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset environment\n",
        "import os, shutil\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install fastparquet pyarrow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZMVFAY9TBGb",
        "outputId": "6ad647cb-182b-496c-d4f3-8cb86086aa0b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2024.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (18.1.0)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2.0.2)\n",
            "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2.11.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from fastparquet) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from fastparquet) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.17.0)\n",
            "Downloading fastparquet-2024.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fastparquet\n",
            "Successfully installed fastparquet-2024.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "path = \"/content/drive/MyDrive/flight_delay_analysis_project/Data_Processed/cleaned_flights.parquet\"\n",
        "\n",
        "df = spark.read.parquet(path)\n",
        "\n",
        "df.printSchema()\n",
        "df.show(10)\n",
        "df.limit(5).toPandas()   # Only convert small part\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PdXlcnTIUtxx",
        "outputId": "ef8e731b-1b80-4722-fcd0-597ce72caa68"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- YEAR: integer (nullable = true)\n",
            " |-- MONTH: integer (nullable = true)\n",
            " |-- AIRLINE: string (nullable = true)\n",
            " |-- DAY: integer (nullable = true)\n",
            " |-- DAY_OF_WEEK: integer (nullable = true)\n",
            " |-- FLIGHT_NUMBER: integer (nullable = true)\n",
            " |-- TAIL_NUMBER: string (nullable = true)\n",
            " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
            " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
            " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
            " |-- DEPARTURE_TIME: integer (nullable = true)\n",
            " |-- DEPARTURE_DELAY: double (nullable = true)\n",
            " |-- TAXI_OUT: integer (nullable = true)\n",
            " |-- WHEELS_OFF: integer (nullable = true)\n",
            " |-- SCHEDULED_TIME: integer (nullable = true)\n",
            " |-- ELAPSED_TIME: integer (nullable = true)\n",
            " |-- AIR_TIME: double (nullable = true)\n",
            " |-- DISTANCE: double (nullable = true)\n",
            " |-- WHEELS_ON: integer (nullable = true)\n",
            " |-- TAXI_IN: integer (nullable = true)\n",
            " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
            " |-- ARRIVAL_TIME: integer (nullable = true)\n",
            " |-- ARRIVAL_DELAY: double (nullable = true)\n",
            " |-- DIVERTED: integer (nullable = true)\n",
            " |-- CANCELLED: integer (nullable = true)\n",
            " |-- CANCELLATION_REASON: string (nullable = true)\n",
            " |-- AIR_SYSTEM_DELAY: integer (nullable = true)\n",
            " |-- AIRLINE_DELAY: integer (nullable = true)\n",
            " |-- TOTAL_DELAY: double (nullable = true)\n",
            " |-- ON_TIME_FLAG: integer (nullable = true)\n",
            " |-- DEP_HOUR: integer (nullable = true)\n",
            " |-- carrier_name: string (nullable = true)\n",
            " |-- AIRPORT: string (nullable = true)\n",
            " |-- airport_name: string (nullable = true)\n",
            " |-- arr_flights: double (nullable = true)\n",
            " |-- arr_del15: double (nullable = true)\n",
            " |-- carrier_ct: double (nullable = true)\n",
            " |-- weather_ct: double (nullable = true)\n",
            " |-- nas_ct: double (nullable = true)\n",
            " |-- security_ct: double (nullable = true)\n",
            " |-- late_aircraft_ct: double (nullable = true)\n",
            " |-- arr_cancelled: double (nullable = true)\n",
            " |-- arr_diverted: double (nullable = true)\n",
            " |-- agg_arr_delay: double (nullable = true)\n",
            " |-- agg_carrier_delay: double (nullable = true)\n",
            " |-- nas_delay: double (nullable = true)\n",
            "\n",
            "+----+-----+-------+---+-----------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+-------------+-----------+------------+--------+--------------------+-------+--------------------+-----------+---------+----------+----------+------+-----------+----------------+-------------+------------+-------------+-----------------+---------+\n",
            "|YEAR|MONTH|AIRLINE|DAY|DAY_OF_WEEK|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|CANCELLATION_REASON|AIR_SYSTEM_DELAY|AIRLINE_DELAY|TOTAL_DELAY|ON_TIME_FLAG|DEP_HOUR|        carrier_name|AIRPORT|        airport_name|arr_flights|arr_del15|carrier_ct|weather_ct|nas_ct|security_ct|late_aircraft_ct|arr_cancelled|arr_diverted|agg_arr_delay|agg_carrier_delay|nas_delay|\n",
            "+----+-----+-------+---+-----------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+-------------+-----------+------------+--------+--------------------+-------+--------------------+-----------+---------+----------+----------+------+-----------+----------------+-------------+------------+-------------+-----------------+---------+\n",
            "|2015|    1|     OO|  1|          4|         5467|     N701BR|           ONT|                SFO|                500|           513|           13.0|      19|       532|            89|          85|    61.0|   363.0|      633|      5|              629|         638|          9.0|       0|        0|               NULL|            NULL|         NULL|       22.0|           0|       5|SkyWest Airlines ...|    RNO|Reno, NV: Reno/Ta...|      257.0|     45.0|     14.37|      0.95|   7.8|       0.81|           21.06|          3.0|         0.0|       3084.0|           1107.0|    295.0|\n",
            "|2015|    1|     OO|  1|          4|         5467|     N701BR|           ONT|                SFO|                500|           513|           13.0|      19|       532|            89|          85|    61.0|   363.0|      633|      5|              629|         638|          9.0|       0|        0|               NULL|            NULL|         NULL|       22.0|           0|       5|SkyWest Airlines ...|    LAX|Los Angeles, CA: ...|     4188.0|    819.0|     128.5|     13.46|242.28|       0.82|          433.93|         50.0|         2.0|      46448.0|          10896.0|   7322.0|\n",
            "|2015|    1|     OO|  1|          4|         5467|     N701BR|           ONT|                SFO|                500|           513|           13.0|      19|       532|            89|          85|    61.0|   363.0|      633|      5|              629|         638|          9.0|       0|        0|               NULL|            NULL|         NULL|       22.0|           0|       5|SkyWest Airlines ...|    SAN|San Diego, CA: Sa...|      716.0|    126.0|     42.19|       1.0| 19.47|        0.0|           63.34|          5.0|         0.0|       6387.0|           2052.0|    624.0|\n",
            "|2015|    1|     OO|  1|          4|         5467|     N701BR|           ONT|                SFO|                500|           513|           13.0|      19|       532|            89|          85|    61.0|   363.0|      633|      5|              629|         638|          9.0|       0|        0|               NULL|            NULL|         NULL|       22.0|           0|       5|SkyWest Airlines ...|    CLD|Carlsbad, CA: McC...|      204.0|     27.0|      8.15|       0.0|  7.14|        0.0|            11.7|          4.0|         1.0|       1016.0|            424.0|    189.0|\n",
            "|2015|    1|     OO|  1|          4|         5467|     N701BR|           ONT|                SFO|                500|           513|           13.0|      19|       532|            89|          85|    61.0|   363.0|      633|      5|              629|         638|          9.0|       0|        0|               NULL|            NULL|         NULL|       22.0|           0|       5|SkyWest Airlines ...|    LAR|Laramie, WY: Lara...|       62.0|     13.0|      5.63|      0.45|  3.56|        0.0|            3.36|          1.0|         1.0|        779.0|            387.0|    179.0|\n",
            "|2015|    1|     OO|  1|          4|         5467|     N701BR|           ONT|                SFO|                500|           513|           13.0|      19|       532|            89|          85|    61.0|   363.0|      633|      5|              629|         638|          9.0|       0|        0|               NULL|            NULL|         NULL|       22.0|           0|       5|SkyWest Airlines ...|    SFO|San Francisco, CA...|     3567.0|    977.0|     91.52|      6.22|384.21|        0.0|          495.04|        132.0|        21.0|      68807.0|           8496.0|  24530.0|\n",
            "|2015|    1|     OO|  1|          4|         5467|     N701BR|           ONT|                SFO|                500|           513|           13.0|      19|       532|            89|          85|    61.0|   363.0|      633|      5|              629|         638|          9.0|       0|        0|               NULL|            NULL|         NULL|       22.0|           0|       5|SkyWest Airlines ...|    DEN|Denver, CO: Denve...|     3594.0|    992.0|    165.78|      23.7|288.84|       2.12|          511.57|        138.0|         8.0|      69200.0|          16853.0|  13009.0|\n",
            "|2015|    1|     OO|  1|          4|         5467|     N701BR|           ONT|                SFO|                500|           513|           13.0|      19|       532|            89|          85|    61.0|   363.0|      633|      5|              629|         638|          9.0|       0|        0|               NULL|            NULL|         NULL|       22.0|           0|       5|SkyWest Airlines ...|    SBA|Santa Barbara, CA...|      575.0|    112.0|     29.21|       1.0| 15.27|       0.75|           65.78|         14.0|         2.0|       7274.0|           1933.0|    420.0|\n",
            "|2015|    1|     OO|  1|          4|         5467|     N701BR|           ONT|                SFO|                500|           513|           13.0|      19|       532|            89|          85|    61.0|   363.0|      633|      5|              629|         638|          9.0|       0|        0|               NULL|            NULL|         NULL|       22.0|           0|       5|SkyWest Airlines ...|    ONT|Ontario, CA: Onta...|      453.0|     95.0|     30.91|       3.1| 18.29|        0.0|            42.7|          6.0|         0.0|       5864.0|           2026.0|    601.0|\n",
            "|2015|    1|     OO|  1|          4|         5467|     N701BR|           ONT|                SFO|                500|           513|           13.0|      19|       532|            89|          85|    61.0|   363.0|      633|      5|              629|         638|          9.0|       0|        0|               NULL|            NULL|         NULL|       22.0|           0|       5|SkyWest Airlines ...|    MKE|Milwaukee, WI: Ge...|      622.0|    219.0|     63.06|      15.2| 58.85|        0.0|           81.89|         30.0|         0.0|      14719.0|           3926.0|   2666.0|\n",
            "+----+-----+-------+---+-----------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+-------------+-----------+------------+--------+--------------------+-------+--------------------+-----------+---------+----------+----------+------+-----------+----------------+-------------+------------+-------------+-----------------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   YEAR  MONTH AIRLINE  DAY  DAY_OF_WEEK  FLIGHT_NUMBER TAIL_NUMBER  \\\n",
              "0  2015      1      OO    1            4           5467      N701BR   \n",
              "1  2015      1      OO    1            4           5467      N701BR   \n",
              "2  2015      1      OO    1            4           5467      N701BR   \n",
              "3  2015      1      OO    1            4           5467      N701BR   \n",
              "4  2015      1      OO    1            4           5467      N701BR   \n",
              "\n",
              "  ORIGIN_AIRPORT DESTINATION_AIRPORT  SCHEDULED_DEPARTURE  ...  carrier_ct  \\\n",
              "0            ONT                 SFO                  500  ...       14.37   \n",
              "1            ONT                 SFO                  500  ...      128.50   \n",
              "2            ONT                 SFO                  500  ...       42.19   \n",
              "3            ONT                 SFO                  500  ...        8.15   \n",
              "4            ONT                 SFO                  500  ...        5.63   \n",
              "\n",
              "   weather_ct  nas_ct  security_ct  late_aircraft_ct  arr_cancelled  \\\n",
              "0        0.95    7.80         0.81             21.06            3.0   \n",
              "1       13.46  242.28         0.82            433.93           50.0   \n",
              "2        1.00   19.47         0.00             63.34            5.0   \n",
              "3        0.00    7.14         0.00             11.70            4.0   \n",
              "4        0.45    3.56         0.00              3.36            1.0   \n",
              "\n",
              "   arr_diverted  agg_arr_delay  agg_carrier_delay  nas_delay  \n",
              "0           0.0         3084.0             1107.0      295.0  \n",
              "1           2.0        46448.0            10896.0     7322.0  \n",
              "2           0.0         6387.0             2052.0      624.0  \n",
              "3           1.0         1016.0              424.0      189.0  \n",
              "4           1.0          779.0              387.0      179.0  \n",
              "\n",
              "[5 rows x 46 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-15dde58a-5946-443a-82b8-1a2c71132adb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>AIRLINE</th>\n",
              "      <th>DAY</th>\n",
              "      <th>DAY_OF_WEEK</th>\n",
              "      <th>FLIGHT_NUMBER</th>\n",
              "      <th>TAIL_NUMBER</th>\n",
              "      <th>ORIGIN_AIRPORT</th>\n",
              "      <th>DESTINATION_AIRPORT</th>\n",
              "      <th>SCHEDULED_DEPARTURE</th>\n",
              "      <th>...</th>\n",
              "      <th>carrier_ct</th>\n",
              "      <th>weather_ct</th>\n",
              "      <th>nas_ct</th>\n",
              "      <th>security_ct</th>\n",
              "      <th>late_aircraft_ct</th>\n",
              "      <th>arr_cancelled</th>\n",
              "      <th>arr_diverted</th>\n",
              "      <th>agg_arr_delay</th>\n",
              "      <th>agg_carrier_delay</th>\n",
              "      <th>nas_delay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>OO</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5467</td>\n",
              "      <td>N701BR</td>\n",
              "      <td>ONT</td>\n",
              "      <td>SFO</td>\n",
              "      <td>500</td>\n",
              "      <td>...</td>\n",
              "      <td>14.37</td>\n",
              "      <td>0.95</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.81</td>\n",
              "      <td>21.06</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3084.0</td>\n",
              "      <td>1107.0</td>\n",
              "      <td>295.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>OO</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5467</td>\n",
              "      <td>N701BR</td>\n",
              "      <td>ONT</td>\n",
              "      <td>SFO</td>\n",
              "      <td>500</td>\n",
              "      <td>...</td>\n",
              "      <td>128.50</td>\n",
              "      <td>13.46</td>\n",
              "      <td>242.28</td>\n",
              "      <td>0.82</td>\n",
              "      <td>433.93</td>\n",
              "      <td>50.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>46448.0</td>\n",
              "      <td>10896.0</td>\n",
              "      <td>7322.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>OO</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5467</td>\n",
              "      <td>N701BR</td>\n",
              "      <td>ONT</td>\n",
              "      <td>SFO</td>\n",
              "      <td>500</td>\n",
              "      <td>...</td>\n",
              "      <td>42.19</td>\n",
              "      <td>1.00</td>\n",
              "      <td>19.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>63.34</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6387.0</td>\n",
              "      <td>2052.0</td>\n",
              "      <td>624.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>OO</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5467</td>\n",
              "      <td>N701BR</td>\n",
              "      <td>ONT</td>\n",
              "      <td>SFO</td>\n",
              "      <td>500</td>\n",
              "      <td>...</td>\n",
              "      <td>8.15</td>\n",
              "      <td>0.00</td>\n",
              "      <td>7.14</td>\n",
              "      <td>0.00</td>\n",
              "      <td>11.70</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1016.0</td>\n",
              "      <td>424.0</td>\n",
              "      <td>189.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>1</td>\n",
              "      <td>OO</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5467</td>\n",
              "      <td>N701BR</td>\n",
              "      <td>ONT</td>\n",
              "      <td>SFO</td>\n",
              "      <td>500</td>\n",
              "      <td>...</td>\n",
              "      <td>5.63</td>\n",
              "      <td>0.45</td>\n",
              "      <td>3.56</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.36</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>779.0</td>\n",
              "      <td>387.0</td>\n",
              "      <td>179.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 46 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15dde58a-5946-443a-82b8-1a2c71132adb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-15dde58a-5946-443a-82b8-1a2c71132adb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-15dde58a-5946-443a-82b8-1a2c71132adb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-001ee830-fc44-455a-80ed-bacaff676084\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-001ee830-fc44-455a-80ed-bacaff676084')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-001ee830-fc44-455a-80ed-bacaff676084 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = df.sample(withReplacement=False, fraction=0.05)\n",
        "\n",
        "sample_path = \"/content/drive/MyDrive/flight_delay_analysis_project/Data_Processed/dashboard_sample.parquet\"\n",
        "\n",
        "sample_df.write.mode(\"overwrite\").parquet(sample_path)\n",
        "\n",
        "print(\"Sample ready at:\", sample_path)\n",
        "print(\"Rows in sample:\", sample_df.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hloHKSXrYM9k",
        "outputId": "7a9b9742-2dc1-48b9-c6e2-38e1c766df55"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample ready at: /content/drive/MyDrive/flight_delay_analysis_project/Data_Processed/dashboard_sample.parquet\n",
            "Rows in sample: 31113571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.1-bin-hadoop3\""
      ],
      "metadata": {
        "id": "pMx4hAGLpdJf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n"
      ],
      "metadata": {
        "id": "GhxrRuSdOg_o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import os\n",
        "\n",
        "# Stop any existing Spark session to ensure clean configuration\n",
        "if 'spark' in locals() and spark.sparkContext._jsc is not None:\n",
        "    spark.stop()\n",
        "\n",
        "spark = (SparkSession.builder\n",
        "    .appName(\"Quick_Preview\")\n",
        "    .master(\"local[*]\")\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"2\")\n",
        "    .config(\"spark.driver.memory\", \"2g\")\n",
        "    .config(\"spark.executor.memory\", \"2g\")\n",
        "    .config(\"spark.ui.showConsoleProgress\", \"false\")\n",
        "    .config(\"spark.local.dir\", \"/content/spark_tmp\") # Ensure stable local directory\n",
        "    .getOrCreate())\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(\"/content/spark_tmp\", exist_ok=True)\n",
        "\n",
        "print(\"✅ Spark ready\")\n",
        "print(f\"Spark local directory set to: {spark.conf.get('spark.local.dir')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lfix_CDLpeoy",
        "outputId": "99f34cd5-d684-4239-d68a-99528210c41a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Spark ready\n",
            "Spark local directory set to: /content/spark_tmp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/drive/MyDrive/flight_delay_analysis_project\"\n",
        "raw_path  = f\"{base_path}/Data\"\n",
        "proc_path = f\"{base_path}/Data_Processed\"\n"
      ],
      "metadata": {
        "id": "0nUPf1MIprYq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq28uLFyCgB",
        "outputId": "64ab168b-d2dc-4288-b0e3-5f14459806f9"
      },
      "source": [
        "# Strategy: keep rows where core fields exist; fill numeric delay columns with 0 only if truly missing.\n",
        "# (You can relax/tighten this later if needed.)\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Drop flights with missing airline/year/month/origin/destination\n",
        "required = [\"YEAR\",\"MONTH\",\"AIRLINE\",\"ORIGIN_AIRPORT\",\"DESTINATION_AIRPORT\"]\n",
        "flights_clean = flights_df\n",
        "for c in required:\n",
        "    flights_clean = flights_clean.filter(col(c).isNotNull())\n",
        "\n",
        "# Fill delay numeric columns (when null) with 0\n",
        "flights_clean = flights_clean.fillna({\n",
        "    \"DEPARTURE_DELAY\": 0.0,\n",
        "    \"ARRIVAL_DELAY\":   0.0\n",
        "})\n",
        "\n",
        "print(\"Rows after basic cleaning:\", flights_clean.count())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows after basic cleaning: 5819079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.range(5).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxAZxtfGpupW",
        "outputId": "7f057353-7202-438d-dae3-37e88006737f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "| id|\n",
            "+---+\n",
            "|  0|\n",
            "|  1|\n",
            "|  2|\n",
            "|  3|\n",
            "|  4|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flights_df = spark.read.csv(f\"{raw_path}/flights.csv\", header=True, inferSchema=True)\n",
        "delay_df   = spark.read.csv(f\"{raw_path}/Airline_Delay_Cause.csv\", header=True, inferSchema=True)\n",
        "\n",
        "print(f\"flights_df rows: {flights_df.count():,}\")\n",
        "print(f\"delay_df rows:   {delay_df.count():,}\")\n",
        "\n",
        "flights_df.printSchema()\n",
        "delay_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNrhleB8BYsV",
        "outputId": "986ceb47-ca0b-4dc4-d2db-4d14a93065f1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flights_df rows: 5,819,079\n",
            "delay_df rows:   375,219\n",
            "root\n",
            " |-- YEAR: integer (nullable = true)\n",
            " |-- MONTH: integer (nullable = true)\n",
            " |-- DAY: integer (nullable = true)\n",
            " |-- DAY_OF_WEEK: integer (nullable = true)\n",
            " |-- AIRLINE: string (nullable = true)\n",
            " |-- FLIGHT_NUMBER: integer (nullable = true)\n",
            " |-- TAIL_NUMBER: string (nullable = true)\n",
            " |-- ORIGIN_AIRPORT: string (nullable = true)\n",
            " |-- DESTINATION_AIRPORT: string (nullable = true)\n",
            " |-- SCHEDULED_DEPARTURE: integer (nullable = true)\n",
            " |-- DEPARTURE_TIME: integer (nullable = true)\n",
            " |-- DEPARTURE_DELAY: integer (nullable = true)\n",
            " |-- TAXI_OUT: integer (nullable = true)\n",
            " |-- WHEELS_OFF: integer (nullable = true)\n",
            " |-- SCHEDULED_TIME: integer (nullable = true)\n",
            " |-- ELAPSED_TIME: integer (nullable = true)\n",
            " |-- AIR_TIME: integer (nullable = true)\n",
            " |-- DISTANCE: integer (nullable = true)\n",
            " |-- WHEELS_ON: integer (nullable = true)\n",
            " |-- TAXI_IN: integer (nullable = true)\n",
            " |-- SCHEDULED_ARRIVAL: integer (nullable = true)\n",
            " |-- ARRIVAL_TIME: integer (nullable = true)\n",
            " |-- ARRIVAL_DELAY: integer (nullable = true)\n",
            " |-- DIVERTED: integer (nullable = true)\n",
            " |-- CANCELLED: integer (nullable = true)\n",
            " |-- CANCELLATION_REASON: string (nullable = true)\n",
            " |-- AIR_SYSTEM_DELAY: integer (nullable = true)\n",
            " |-- SECURITY_DELAY: integer (nullable = true)\n",
            " |-- AIRLINE_DELAY: integer (nullable = true)\n",
            " |-- LATE_AIRCRAFT_DELAY: integer (nullable = true)\n",
            " |-- WEATHER_DELAY: integer (nullable = true)\n",
            "\n",
            "root\n",
            " |-- year: integer (nullable = true)\n",
            " |-- month: integer (nullable = true)\n",
            " |-- carrier: string (nullable = true)\n",
            " |-- carrier_name: string (nullable = true)\n",
            " |-- airport: string (nullable = true)\n",
            " |-- airport_name: string (nullable = true)\n",
            " |-- arr_flights: double (nullable = true)\n",
            " |-- arr_del15: double (nullable = true)\n",
            " |-- carrier_ct: double (nullable = true)\n",
            " |-- weather_ct: double (nullable = true)\n",
            " |-- nas_ct: double (nullable = true)\n",
            " |-- security_ct: double (nullable = true)\n",
            " |-- late_aircraft_ct: double (nullable = true)\n",
            " |-- arr_cancelled: double (nullable = true)\n",
            " |-- arr_diverted: double (nullable = true)\n",
            " |-- arr_delay: double (nullable = true)\n",
            " |-- carrier_delay: double (nullable = true)\n",
            " |-- weather_delay: double (nullable = true)\n",
            " |-- nas_delay: double (nullable = true)\n",
            " |-- security_delay: double (nullable = true)\n",
            " |-- late_aircraft_delay: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, when, count, isnan\n",
        "\n",
        "def nulls_per_col(df):\n",
        "    exprs = [count(when(col(c).isNull() | isnan(c), c)).alias(c) for c in df.columns]\n",
        "    return df.select(exprs)\n",
        "\n",
        "print(\"Nulls in flights_df:\")\n",
        "nulls_per_col(flights_df).show(truncate=False)\n",
        "\n",
        "print(\"Nulls in delay_df:\")\n",
        "nulls_per_col(delay_df).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZsm-pJYBZNC",
        "outputId": "43d266dc-9bfc-498c-eb64-8ec6d071ac47"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nulls in flights_df:\n",
            "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
            "|YEAR|MONTH|DAY|DAY_OF_WEEK|AIRLINE|FLIGHT_NUMBER|TAIL_NUMBER|ORIGIN_AIRPORT|DESTINATION_AIRPORT|SCHEDULED_DEPARTURE|DEPARTURE_TIME|DEPARTURE_DELAY|TAXI_OUT|WHEELS_OFF|SCHEDULED_TIME|ELAPSED_TIME|AIR_TIME|DISTANCE|WHEELS_ON|TAXI_IN|SCHEDULED_ARRIVAL|ARRIVAL_TIME|ARRIVAL_DELAY|DIVERTED|CANCELLED|CANCELLATION_REASON|AIR_SYSTEM_DELAY|SECURITY_DELAY|AIRLINE_DELAY|LATE_AIRCRAFT_DELAY|WEATHER_DELAY|\n",
            "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
            "|0   |0    |0  |0          |0      |0            |14721      |0             |0                  |0                  |86153         |86153          |89047   |89047     |6             |105071      |105071  |0       |92513    |92513  |0                |92513       |105071       |0       |0        |5729195            |4755640         |4755640       |4755640      |4755640            |4755640      |\n",
            "+----+-----+---+-----------+-------+-------------+-----------+--------------+-------------------+-------------------+--------------+---------------+--------+----------+--------------+------------+--------+--------+---------+-------+-----------------+------------+-------------+--------+---------+-------------------+----------------+--------------+-------------+-------------------+-------------+\n",
            "\n",
            "Nulls in delay_df:\n",
            "+----+-----+-------+------------+-------+------------+-----------+---------+----------+----------+------+-----------+----------------+-------------+------------+---------+-------------+-------------+---------+--------------+-------------------+\n",
            "|year|month|carrier|carrier_name|airport|airport_name|arr_flights|arr_del15|carrier_ct|weather_ct|nas_ct|security_ct|late_aircraft_ct|arr_cancelled|arr_diverted|arr_delay|carrier_delay|weather_delay|nas_delay|security_delay|late_aircraft_delay|\n",
            "+----+-----+-------+------------+-------+------------+-----------+---------+----------+----------+------+-----------+----------------+-------------+------------+---------+-------------+-------------+---------+--------------+-------------------+\n",
            "|0   |0    |0      |0           |0      |0           |636        |931      |636       |636       |636   |636        |636             |636          |636         |636      |636          |636          |636      |636           |636                |\n",
            "+----+-----+-------+------------+-------+------------+-----------+---------+----------+----------+------+-----------+----------------+-------------+------------+---------+-------------+-------------+---------+--------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import upper\n",
        "\n",
        "# Ensure key columns are consistent case/types\n",
        "# flights: YEAR, MONTH, AIRLINE, ORIGIN_AIRPORT, DESTINATION_AIRPORT, DEPARTURE_DELAY, ARRIVAL_DELAY, DISTANCE, AIR_TIME\n",
        "flights_df = (flights_df\n",
        "              .withColumn(\"YEAR\",  col(\"YEAR\").cast(\"int\"))\n",
        "              .withColumn(\"MONTH\", col(\"MONTH\").cast(\"int\"))\n",
        "              .withColumn(\"AIRLINE\", upper(col(\"AIRLINE\")))\n",
        "              .withColumn(\"DEPARTURE_DELAY\", col(\"DEPARTURE_DELAY\").cast(\"double\"))\n",
        "              .withColumn(\"ARRIVAL_DELAY\",   col(\"ARRIVAL_DELAY\").cast(\"double\"))\n",
        "              .withColumn(\"DISTANCE\",        col(\"DISTANCE\").cast(\"double\"))\n",
        "              .withColumn(\"AIR_TIME\",        col(\"AIR_TIME\").cast(\"double\"))\n",
        "             )\n",
        "\n",
        "# delay_df uses (year, month, carrier, airport, ... cause counts/minutes)\n",
        "delay_df = (delay_df\n",
        "            .withColumnRenamed(\"year\", \"YEAR\")\n",
        "            .withColumnRenamed(\"month\", \"MONTH\")\n",
        "            .withColumnRenamed(\"carrier\", \"AIRLINE\")\n",
        "            .withColumnRenamed(\"airport\", \"AIRPORT\")\n",
        "            .withColumn(\"YEAR\",  col(\"YEAR\").cast(\"int\"))\n",
        "            .withColumn(\"MONTH\", col(\"MONTH\").cast(\"int\"))\n",
        "            .withColumn(\"AIRLINE\", upper(col(\"AIRLINE\")))\n",
        "           )\n",
        "\n",
        "flights_df.select(\"YEAR\",\"MONTH\",\"AIRLINE\",\"ORIGIN_AIRPORT\",\"DESTINATION_AIRPORT\",\"DEPARTURE_DELAY\",\"ARRIVAL_DELAY\",\"DISTANCE\").show(5)\n",
        "delay_df.select(\"YEAR\",\"MONTH\",\"AIRLINE\",\"AIRPORT\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGIrdGCDB09-",
        "outputId": "24ff3ac6-c7bf-49cd-b737-d52b481553cf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-------+--------------+-------------------+---------------+-------------+--------+\n",
            "|YEAR|MONTH|AIRLINE|ORIGIN_AIRPORT|DESTINATION_AIRPORT|DEPARTURE_DELAY|ARRIVAL_DELAY|DISTANCE|\n",
            "+----+-----+-------+--------------+-------------------+---------------+-------------+--------+\n",
            "|2015|    1|     AS|           ANC|                SEA|          -11.0|        -22.0|  1448.0|\n",
            "|2015|    1|     AA|           LAX|                PBI|           -8.0|         -9.0|  2330.0|\n",
            "|2015|    1|     US|           SFO|                CLT|           -2.0|          5.0|  2296.0|\n",
            "|2015|    1|     AA|           LAX|                MIA|           -5.0|         -9.0|  2342.0|\n",
            "|2015|    1|     AS|           SEA|                ANC|           -1.0|        -21.0|  1448.0|\n",
            "+----+-----+-------+--------------+-------------------+---------------+-------------+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----+-----+-------+-------+\n",
            "|YEAR|MONTH|AIRLINE|AIRPORT|\n",
            "+----+-----+-------+-------+\n",
            "|2025|    6|     9E|    ABE|\n",
            "|2025|    6|     9E|    ABY|\n",
            "|2025|    6|     9E|    AEX|\n",
            "|2025|    6|     9E|    AGS|\n",
            "|2025|    6|     9E|    ALB|\n",
            "+----+-----+-------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Strategy: keep rows where core fields exist; fill numeric delay columns with 0 only if truly missing.\n",
        "# (You can relax/tighten this later if needed.)\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Drop flights with missing airline/year/month/origin/destination\n",
        "required = [\"YEAR\",\"MONTH\",\"AIRLINE\",\"ORIGIN_AIRPORT\",\"DESTINATION_AIRPORT\"]\n",
        "flights_clean = flights_df\n",
        "for c in required:\n",
        "    flights_clean = flights_clean.filter(col(c).isNotNull())\n",
        "\n",
        "# Fill delay numeric columns (when null) with 0\n",
        "flights_clean = flights_clean.fillna({\n",
        "    \"DEPARTURE_DELAY\": 0.0,\n",
        "    \"ARRIVAL_DELAY\":   0.0\n",
        "})\n",
        "\n",
        "print(\"Rows after basic cleaning:\", flights_clean.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq28uLFyCqgB",
        "outputId": "a71441dc-58c9-4f7c-c336-2239b2b163ac"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows after basic cleaning: 5819079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when, lit, floor\n",
        "\n",
        "# TOTAL_DELAY and ON_TIME_FLAG (1 if ARRIVAL_DELAY<=0 else 0)\n",
        "flights_enriched = (flights_clean\n",
        "    .withColumn(\"TOTAL_DELAY\", col(\"DEPARTURE_DELAY\") + col(\"ARRIVAL_DELAY\"))\n",
        "    .withColumn(\"ON_TIME_FLAG\", when(col(\"ARRIVAL_DELAY\") <= 0, lit(1)).otherwise(lit(0)))\n",
        ")\n",
        "\n",
        "# Optional: Departure hour bucket (if SCHEDULED_DEPARTURE exists as minutes like 0..2359)\n",
        "if \"SCHEDULED_DEPARTURE\" in flights_enriched.columns:\n",
        "    flights_enriched = flights_enriched.withColumn(\n",
        "        \"DEP_HOUR\", floor(col(\"SCHEDULED_DEPARTURE\")/100).cast(\"int\")\n",
        "    )\n",
        "\n",
        "flights_enriched.select(\"YEAR\",\"MONTH\",\"AIRLINE\",\"ORIGIN_AIRPORT\",\"ARRIVAL_DELAY\",\"TOTAL_DELAY\",\"ON_TIME_FLAG\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCCV-m9tCrDK",
        "outputId": "cf4d137c-0ff5-4bf4-a182-e3ab8194db21"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-------+--------------+-------------+-----------+------------+\n",
            "|YEAR|MONTH|AIRLINE|ORIGIN_AIRPORT|ARRIVAL_DELAY|TOTAL_DELAY|ON_TIME_FLAG|\n",
            "+----+-----+-------+--------------+-------------+-----------+------------+\n",
            "|2015|    1|     AS|           ANC|        -22.0|      -33.0|           1|\n",
            "|2015|    1|     AA|           LAX|         -9.0|      -17.0|           1|\n",
            "|2015|    1|     US|           SFO|          5.0|        3.0|           0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|      -14.0|           1|\n",
            "|2015|    1|     AS|           SEA|        -21.0|      -22.0|           1|\n",
            "|2015|    1|     DL|           SFO|          8.0|        3.0|           0|\n",
            "|2015|    1|     NK|           LAS|        -17.0|      -23.0|           1|\n",
            "|2015|    1|     US|           LAX|        -10.0|        4.0|           1|\n",
            "|2015|    1|     AA|           SFO|        -13.0|      -24.0|           1|\n",
            "|2015|    1|     DL|           LAS|        -15.0|      -12.0|           1|\n",
            "+----+-----+-------+--------------+-------------+-----------+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will join on YEAR, MONTH, AIRLINE and also try to map the origin airport -> AIRPORT in the aggregated table.\n",
        "# Not all (YEAR,MONTH,AIRLINE,ORIGIN_AIRPORT) will exist in delay_df; left join keeps all flights.\n",
        "\n",
        "join_keys_carrier = [\"YEAR\",\"MONTH\",\"AIRLINE\"]\n",
        "\n",
        "# First: carrier-month level (many rows in delay_df also include AIRPORT; we'll keep both)\n",
        "delay_carrier = delay_df.drop(\"AIRPORT\") if \"AIRPORT\" in delay_df.columns else delay_df\n",
        "\n",
        "joined_df = flights_enriched.join(delay_carrier, on=join_keys_carrier, how=\"left\")\n",
        "\n",
        "# Second (optional): if you want airport-specific aggregates too, do an additional left join on ORIGIN_AIRPORT↔AIRPORT\n",
        "if \"AIRPORT\" in delay_df.columns:\n",
        "    delay_airport = delay_df.select(\"YEAR\",\"MONTH\",\"AIRLINE\",\"AIRPORT\",\n",
        "                                    *[c for c in delay_df.columns if c not in [\"YEAR\",\"MONTH\",\"AIRLINE\",\"AIRPORT\"]])\n",
        "    joined_df = joined_df.join(\n",
        "        delay_airport.withColumnRenamed(\"AIRPORT\",\"ORIGIN_AIRPORT\"),\n",
        "        on=[\"YEAR\",\"MONTH\",\"AIRLINE\",\"ORIGIN_AIRPORT\"],\n",
        "        how=\"left\"\n",
        "    )\n",
        "\n",
        "joined_df.select(\"YEAR\",\"MONTH\",\"AIRLINE\",\"ORIGIN_AIRPORT\",\"ARRIVAL_DELAY\").show(25)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN72_5w0C9jM",
        "outputId": "ff8e9a45-4f52-4053-8953-dc386edd5841"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+-------+--------------+-------------+\n",
            "|YEAR|MONTH|AIRLINE|ORIGIN_AIRPORT|ARRIVAL_DELAY|\n",
            "+----+-----+-------+--------------+-------------+\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "|2015|    1|     AA|           LAX|         -9.0|\n",
            "+----+-----+-------+--------------+-------------+\n",
            "only showing top 25 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!df -h\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tT9HMMXLNXQ",
        "outputId": "289c5a0b-9fd6-4efe-b372-d31ed2ed8654"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         108G   41G   68G  38% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "shm             5.8G     0  5.8G   0% /dev/shm\n",
            "/dev/root       2.0G  1.2G  750M  62% /usr/sbin/docker-init\n",
            "tmpfs           6.4G  1.3M  6.4G   1% /var/colab\n",
            "/dev/sda1       114G  103G   12G  90% /kaggle/input\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n",
            "drive            15G  6.3G  8.8G  42% /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /tmp/*\n",
        "!df -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smYMfgXGMGOx",
        "outputId": "e90b9fb4-c468-4eef-9471-3907af82ed17"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         108G   41G   68G  38% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "shm             5.8G     0  5.8G   0% /dev/shm\n",
            "/dev/root       2.0G  1.2G  750M  62% /usr/sbin/docker-init\n",
            "tmpfs           6.4G  1.3M  6.4G   1% /var/colab\n",
            "/dev/sda1       114G  103G   12G  90% /kaggle/input\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n",
            "drive            15G  6.3G  8.8G  42% /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- SAFE, FAST VERSION ----\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Drop duplicates based on key columns only (faster & memory safe)\n",
        "joined_df = joined_df.dropDuplicates([\"YEAR\",\"MONTH\",\"AIRLINE\",\n",
        "                                      \"FLIGHT_NUMBER\",\"ORIGIN_AIRPORT\",\"DESTINATION_AIRPORT\"])\n",
        "\n",
        "print(\"Deduplication applied on key columns (no full count executed).\")\n",
        "\n",
        "# Apply basic sanity filters without triggering large scans\n",
        "joined_df = joined_df.filter((col(\"DISTANCE\").isNull()) | (col(\"DISTANCE\") >= 0))\n",
        "joined_df = joined_df.filter((col(\"AIR_TIME\").isNull()) | (col(\"AIR_TIME\") >= 0))\n",
        "\n",
        "print(\"Sanity filters applied successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aglkTXzXDR9F",
        "outputId": "3a6a3614-60bb-47b8-dbc8-e338cb63aea3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deduplication applied on key columns (no full count executed).\n",
            "Sanity filters applied successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your cleaned dataset\n",
        "df = pd.read_parquet(\"/content/drive/MyDrive/flight_delay_analysis_project/Data_Processed/cleaned_flights.parquet\")\n",
        "\n",
        "# Define major hub airport codes\n",
        "hub_codes = [\n",
        "    \"ATL\", \"ORD\", \"DFW\", \"DEN\", \"LAX\", \"CLT\", \"MCO\", \"LAS\", \"PHX\", \"SEA\",\n",
        "    \"SFO\", \"EWR\", \"MIA\", \"IAH\", \"JFK\", \"BOS\", \"MSP\", \"DTW\", \"PHL\", \"LGA\"\n",
        "]\n",
        "\n",
        "# Create new hub indicator columns\n",
        "df[\"ORIGIN_IS_HUB\"] = df[\"ORIGIN_AIRPORT\"].isin(hub_codes).astype(int)\n",
        "df[\"DEST_IS_HUB\"] = df[\"DESTINATION_AIRPORT\"].isin(hub_codes).astype(int)\n",
        "\n",
        "# Save the final dataset (for your Streamlit Dashboard)\n",
        "output = \"/content/drive/MyDrive/flight_delay_analysis_project/Data_Processed/final_flights_with_hubs.parquet\"\n",
        "df.to_parquet(output, index=False)\n",
        "\n",
        "print(\"✔ Final dataset created successfully at:\")\n",
        "print(output)\n",
        "print(\"Rows:\", len(df))\n"
      ],
      "metadata": {
        "id": "PjGKr9OxPgT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df = cleaned_df.sample(withReplacement=False, fraction=0.05)\n",
        "sample_df.write.mode(\"overwrite\").parquet(\"/content/drive/MyDrive/.../sample_for_dashboard.parquet\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "DkG4gSxaQpv9",
        "outputId": "3c9c225d-c092-403f-8e3c-b403427fd269"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cleaned_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2512801764.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaned_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwithReplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfraction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msample_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/.../sample_for_dashboard.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cleaned_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when, lit, col\n",
        "\n",
        "# List of major hub airport codes\n",
        "hub_codes = [\"ATL\",\"ORD\",\"DFW\",\"DEN\",\"LAX\",\"CLT\",\"MCO\",\"LAS\",\"PHX\",\"SEA\",\n",
        "             \"SFO\",\"EWR\",\"MIA\",\"IAH\",\"JFK\",\"BOS\",\"MSP\",\"DTW\",\"PHL\",\"LGA\"]\n",
        "\n",
        "# Create hub flags using built-in Spark SQL functions (no UDF)\n",
        "joined_df = (joined_df\n",
        "    .withColumn(\"ORIGIN_IS_HUB\", when(col(\"ORIGIN_AIRPORT\").isin(hub_codes), lit(1)).otherwise(lit(0)))\n",
        "    .withColumn(\"DEST_IS_HUB\",   when(col(\"DESTINATION_AIRPORT\").isin(hub_codes), lit(1)).otherwise(lit(0)))\n",
        ")\n",
        "\n",
        "joined_df.select(\"ORIGIN_AIRPORT\",\"ORIGIN_IS_HUB\",\"DESTINATION_AIRPORT\",\"DEST_IS_HUB\").show(10, truncate=False)\n",
        "\n",
        "# Save the processed DataFrame to a stable location to avoid temporary file issues\n",
        "output_path = f\"{proc_path}/joined_flights_with_hubs.parquet\"\n",
        "print(f\"Saving processed data to: {output_path}\")\n",
        "joined_df.write.mode(\"overwrite\").parquet(output_path)\n",
        "print(\"✅ Processed DataFrame saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "id": "qXChwpQCDSfF",
        "outputId": "a2d6123a-0adb-40e9-9c33-d1a0a954e782"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------+-------------------+-----------+\n",
            "|ORIGIN_AIRPORT|ORIGIN_IS_HUB|DESTINATION_AIRPORT|DEST_IS_HUB|\n",
            "+--------------+-------------+-------------------+-----------+\n",
            "|ANC           |0            |SEA                |1          |\n",
            "|LAX           |1            |PBI                |0          |\n",
            "|SEA           |1            |ANC                |0          |\n",
            "|SFO           |1            |MSP                |1          |\n",
            "|LAS           |1            |MSP                |1          |\n",
            "|LAS           |1            |ATL                |1          |\n",
            "|DEN           |1            |ATL                |1          |\n",
            "|LAS           |1            |MIA                |1          |\n",
            "|ANC           |0            |SEA                |1          |\n",
            "|SFO           |1            |IAH                |1          |\n",
            "+--------------+-------------+-------------------+-----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Saving processed data to: /content/drive/MyDrive/flight_delay_analysis_project/Data_Processed/joined_flights_with_hubs.parquet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:KeyboardInterrupt while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/socket.py\", line 720, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1030675596.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{proc_path}/joined_flights_with_hubs.parquet\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saving processed data to: {output_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mjoined_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Processed DataFrame saved successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.5.1-bin-hadoop3/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m   1719\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1720\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_opts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1721\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m     def text(\n",
            "\u001b[0;32m/content/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/content/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ps -aux | grep java\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pr9K0V-EKb6",
        "outputId": "d1a6a3f1-be75-4d9b-aa82-8969fe0260c7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root        2702  125 17.0 5239512 2263896 ?     Sl   18:15  96:21 /usr/lib/jvm/java-11-openjdk-amd64/bin/java -cp /content/spark-3.5.1-bin-hadoop3/conf/:/content/spark-3.5.1-bin-hadoop3/jars/* -Xmx2g -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false org.apache.spark.deploy.SparkSubmit --conf spark.executor.memory=2g --conf spark.master=local[*] --conf spark.driver.memory=2g --conf spark.app.name=Quick_Preview --conf spark.sql.shuffle.partitions=2 --conf spark.ui.showConsoleProgress=false pyspark-shell\n",
            "root       22139  0.0  0.0   7376  3528 ?        S    19:31   0:00 /bin/bash -c ps -aux | grep java\n",
            "root       22141  0.0  0.0   6484  2400 ?        S    19:31   0:00 grep java\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "path = \"/content/drive/MyDrive/flight_delay_analysis_project/Data_Processed/joined_flights_with_hubs.parquet\"\n",
        "\n",
        "shutil.rmtree(path, ignore_errors=True)\n",
        "print(\"Deleted incomplete parquet folder successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hfJ4S2EJjxT",
        "outputId": "5f30767a-84cb-43e1-a6ed-8d8d52090d55"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted incomplete parquet folder successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "delay_df = delay_df.withColumnRenamed(\"arr_delay\", \"agg_arr_delay\") \\\n",
        "                   .withColumnRenamed(\"carrier_delay\", \"agg_carrier_delay\") \\\n",
        "                   .withColumnRenamed(\"weather_delay\", \"agg_weather_delay\") \\\n",
        "                   .withColumnRenamed(\"nas_delay\", \"agg_nas_delay\") \\\n",
        "                   .withColumnRenamed(\"security_delay\", \"agg_security_delay\") \\\n",
        "                   .withColumnRenamed(\"late_aircraft_delay\", \"agg_late_aircraft_delay\") \\\n",
        "                   .withColumnRenamed(\"carrier_ct\", \"agg_carrier_ct\") \\\n",
        "                   .withColumnRenamed(\"weather_ct\", \"agg_weather_ct\") \\\n",
        "                   .withColumnRenamed(\"nas_ct\", \"agg_nas_ct\") \\\n",
        "                   .withColumnRenamed(\"security_ct\", \"agg_security_ct\") \\\n",
        "                   .withColumnRenamed(\"late_aircraft_ct\", \"agg_late_aircraft_ct\")"
      ],
      "metadata": {
        "id": "OwrYbmj5M09L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "outputId": "22cdb681-3d68-4067-9106-2916c3e054d6"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Exception while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 516, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
            "    raise Py4JNetworkError(\n",
            "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Py4JError",
          "evalue": "An error occurred while calling o2337.withColumnRenamed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-549288642.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdelay_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelay_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arr_delay\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"agg_arr_delay\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m                    \u001b[0;34m.\u001b[0m\u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"carrier_delay\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"agg_carrier_delay\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                    \u001b[0;34m.\u001b[0m\u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weather_delay\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"agg_weather_delay\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                    \u001b[0;34m.\u001b[0m\u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nas_delay\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"agg_nas_delay\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    \u001b[0;34m.\u001b[0m\u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"security_delay\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"agg_security_delay\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.5.1-bin-hadoop3/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumnRenamed\u001b[0;34m(self, existing, new)\u001b[0m\n\u001b[1;32m   5206\u001b[0m         \u001b[0;34m+\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5207\u001b[0m         \"\"\"\n\u001b[0;32m-> 5208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexisting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwithColumnsRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolsMap\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.5.1-bin-hadoop3/python/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    332\u001b[0m                     format(target_id, \".\", name, value))\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             raise Py4JError(\n\u001b[0m\u001b[1;32m    335\u001b[0m                 \u001b[0;34m\"An error occurred while calling {0}{1}{2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                 format(target_id, \".\", name))\n",
            "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o2337.withColumnRenamed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joined_df = flights_enriched.join(delay_df, [\"YEAR\",\"MONTH\",\"AIRLINE\"], how=\"left\")"
      ],
      "metadata": {
        "id": "iuNZjnV4hV-2"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joined_df.select(\"YEAR\",\"MONTH\",\"AIRLINE\",\"ORIGIN_AIRPORT\",\"ARRIVAL_DELAY\",\n",
        "                 \"agg_arr_delay\",\"agg_carrier_delay\").show(10)\n"
      ],
      "metadata": {
        "id": "CrWeyezbiLej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_path = f\"{proc_path}/cleaned_flights.parquet\"\n"
      ],
      "metadata": {
        "id": "jZER7j_3Anv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([col for col in joined_df.columns if joined_df.columns.count(col) > 1])\n"
      ],
      "metadata": {
        "id": "-EiXViEwF1nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for c in joined_df.columns:\n",
        "    print(repr(c))\n"
      ],
      "metadata": {
        "id": "TR0ST9NFGPhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/drive/MyDrive/flight_delay_analysis_project/Data_Processed/\n"
      ],
      "metadata": {
        "id": "gmpOnxISekyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh \"/content/drive/MyDrive/flight_delay_analysis_project/Data_Processed/cleaned_flights.parquet\"\n"
      ],
      "metadata": {
        "id": "UkUrd8JRkfNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any previous local copy to avoid mixing files\n",
        "!rm -rf /content/cleaned_flights.parquet\n",
        "# Copy from Drive -> local disk\n",
        "!cp -r \"/content/drive/MyDrive/flight_delay_analysis_project/Data_Processed/cleaned_flights.parquet\" /content/\n",
        "# Sanity check\n",
        "!ls -lh /content/cleaned_flights.parquet\n"
      ],
      "metadata": {
        "id": "VbOKgUNwHgWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = (SparkSession.builder\n",
        "         .appName(\"Flight_Delay_Step2_Cleaning\")\n",
        "         .master(\"local[*]\")\n",
        "         .config(\"spark.sql.shuffle.partitions\", \"8\")  # keep small on Colab\n",
        "         .getOrCreate())\n",
        "\n",
        "# Optional: slightly fewer shuffles if you still see slowness\n",
        "# spark.conf.set(\"spark.sql.shuffle.partitions\", \"4\")\n"
      ],
      "metadata": {
        "id": "jsgfxiHHHg2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/cleaned_flights.parquet\n"
      ],
      "metadata": {
        "id": "iv-jtc-jHsKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = spark.read.option(\"mergeSchema\", \"false\").parquet(\"/content/cleaned_flights.parquet\")\n",
        "df_test.printSchema()\n"
      ],
      "metadata": {
        "id": "_O1TXQBDMN1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ⚡ read just 1 parquet part (fast preview)\n",
        "sample_path = \"/content/cleaned_flights.parquet/part-00000-b47ae07b-6e01-4502-a298-c34c0eeae787-c000.snappy.parquet\"\n",
        "\n",
        "df_sample = spark.read.parquet(sample_path)\n",
        "print(\"✅ Loaded single parquet part\")\n",
        "df_sample.show(5)\n"
      ],
      "metadata": {
        "id": "HFkaQayldRm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total records:\", df_sample.count())\n"
      ],
      "metadata": {
        "id": "QoBRL_55ODDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_df = spark.read.option(\"mergeSchema\",\"false\").parquet(\"/content/cleaned_flights.parquet\")\n",
        "print(\"Full cleaned records:\", clean_df.count())\n"
      ],
      "metadata": {
        "id": "HUhDGv8zOId3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg, round as sround\n",
        "\n",
        "df_sample.groupBy(\"AIRLINE\") \\\n",
        "    .agg(sround(avg(\"ARRIVAL_DELAY\"),2).alias(\"AVG_ARR_DELAY\")) \\\n",
        "    .orderBy(\"AVG_ARR_DELAY\", ascending=False) \\\n",
        "    .show(5)\n"
      ],
      "metadata": {
        "id": "6e_27YhTlKQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample.write.mode(\"overwrite\").parquet(\"/content/drive/MyDrive/flight_delay_analysis_project/Outputs/preview_sample.parquet\")\n",
        "print(\"✅ Sample saved to Outputs folder\")\n"
      ],
      "metadata": {
        "id": "HetnYxkflWzL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}